{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade semantic-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add your environment variables before running the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .env-test\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_ENDPOINT=\"\"\n",
    "AZURE_OPENAI_API_KEY=\"\"\n",
    "AZCOSMOS_API=\"mongo-vcore\" # others are not supported yet\n",
    "AZCOSMOS_CONNSTR=\"\"\n",
    "AZCOSMOS_DATABASE_NAME=\"\"\n",
    "AZCOSMOS_CONTAINER_NAME=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the environment variables file\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = config.get(\"AZCOSMOS_DATABASE_NAME\")\n",
    "collection_name = config.get(\"AZCOSMOS_CONTAINER_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"VectorSearchIndex\"\n",
    "vector_dimensions = 1536 # text-embedding-ada-002 uses a 1536-dimensional embedding vector\n",
    "num_lists = 1\n",
    "similarity = \"COS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "async def upsert_data_to_memory_store(memory_store: callable, data_file_path: str):\n",
    "    with open(file=data_file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        n = 0\n",
    "        for item in data:\n",
    "            n+=1\n",
    "            await memory_store.save_information(\n",
    "                collection=collection_name,\n",
    "                id=item[\"id\"],\n",
    "                text=item[\"content\"],\n",
    "                description=item[\"title\"]\n",
    "            )\n",
    "            print(\"Generating embeddings and saving item:\", n, \"/\" ,len(data), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "# get api key and endpoint from .env file\n",
    "_, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "kernel = sk.Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering Azure OpenAI Chat Service...\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding azure openai chat service\n",
    "chat_model_deployment_name = config.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "azure_chat_service = AzureChatCompletion(\n",
    "    deployment_name=chat_model_deployment_name,\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kernel(plugins=KernelPluginCollection(plugins={}), prompt_template_engine=PromptTemplateEngine(), memory=NullMemory(), text_completion_services={'chat-model': <function Kernel.add_text_completion_service.<locals>.<lambda> at 0x000001F1FFB86E60>}, chat_services={'chat-model': <function Kernel.add_chat_service.<locals>.<lambda> at 0x000001F1FFB86DD0>}, text_embedding_generation_services={}, default_text_completion_service='chat-model', default_chat_service='chat-model', default_text_embedding_generation_service=None, retry_mechanism=PassThroughWithoutRetry(), function_invoking_handlers={}, function_invoked_handlers={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.add_chat_service(chat_model_deployment_name, azure_chat_service)\n",
    "print(\"Added Azure OpenAI Chat Service...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering Azure OpenAI Embedding Service...\n"
     ]
    }
   ],
   "source": [
    "# adding azure openai text embedding service\n",
    "embedding_model_deployment_name = config.get(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\")\n",
    "\n",
    "azure_text_embedding_service = AzureTextEmbedding(\n",
    "    deployment_name=embedding_model_deployment_name,\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kernel(plugins=KernelPluginCollection(plugins={}), prompt_template_engine=PromptTemplateEngine(), memory=NullMemory(), text_completion_services={'chat-model': <function Kernel.add_text_completion_service.<locals>.<lambda> at 0x000001F1FFB86E60>}, chat_services={'chat-model': <function Kernel.add_chat_service.<locals>.<lambda> at 0x000001F1FFB86DD0>}, text_embedding_generation_services={'embedding-model': <function Kernel.add_text_embedding_generation_service.<locals>.<lambda> at 0x000001F1F91C5BD0>}, default_text_completion_service='chat-model', default_chat_service='chat-model', default_text_embedding_generation_service='embedding-model', retry_mechanism=PassThroughWithoutRetry(), function_invoking_handlers={}, function_invoked_handlers={})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.add_text_embedding_generation_service(embedding_model_deployment_name, azure_text_embedding_service)\n",
    "print(\"Added Azure OpenAI Embedding Generation Service...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating or updating Azure Cosmos DB Memory Store...\n",
      "Finished updating Azure Cosmos DB Memory Store...\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cosmosdb import (\n",
    "    AzureCosmosDBMemoryStore,\n",
    ")\n",
    "\n",
    "print(\"Creating or updating Azure Cosmos DB Memory Store...\")\n",
    "# create azure cosmos db for mongo db vcore api store and collection with vector ivf\n",
    "# currently SK only supports the ivf vector kind\n",
    "store  = await AzureCosmosDBMemoryStore.create(\n",
    "    database_name=database_name,\n",
    "    collection_name=collection_name,\n",
    "    index_name=index_name,\n",
    "    vector_dimensions=vector_dimensions,\n",
    "    num_lists=num_lists,\n",
    "    similarity=similarity\n",
    ")\n",
    "print(\"Finished updating Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered Azure Cosmos DB Memory Store...\n"
     ]
    }
   ],
   "source": [
    "kernel.register_memory_store(memory_store=store)\n",
    "print(\"Registered Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting data to Azure Cosmos DB Memory Store...\n",
      "Generating embeddings and saving item: 107 / 107\r"
     ]
    }
   ],
   "source": [
    "print(\"Upserting data to Azure Cosmos DB Memory Store...\")\n",
    "await upsert_data_to_memory_store(kernel.memory, \"./text-sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each time it calls the embedding model to generate embeddings from your query\n",
    "query_term = \"What is Azure Database for Managed Instances?\"\n",
    "result = await kernel.memory.search(collection_name, query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is: Azure SQL Managed Instance is a fully managed, scalable, and secure SQL Server instance hosted in Azure. It provides features like automatic backups, monitoring, and high availability. SQL Managed Instance supports various data types, such as JSON, spatial, and full-text. You can use Azure SQL Managed Instance to migrate your existing applications, build new applications, and ensure the performance and security of your data. It also integrates with other Azure services, such as Azure App Service and Azure Data Factory.\n",
      "Relevance Score: 0.8967287909762478\n",
      "Full Record: {\"text\": \"Azure SQL Managed Instance is a fully managed, scalable, and secure SQL Server instance hosted in Azure. It provides features like automatic backups, monitoring, and high availability. SQL Managed Instance supports various data types, such as JSON, spatial, and full-text. You can use Azure SQL Managed Instance to migrate your existing applications, build new applications, and ensure the performance and security of your data. It also integrates with other Azure services, such as Azure App Service and Azure Data Factory.\", \"description\": \"Azure SQL Managed Instance\", \"additional_metadata\": null}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Result is: {result[0].text}\\nRelevance Score: {result[0].relevance}\\nFull Record: {result[0].additional_metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a chatbot that can have a conversations about any topic related to the provided context.\n",
    "    Start by saying how relevant the question is using the provided context relevancy score.\n",
    "    Give explicit answers from the provided context or say 'I don't know' if it does not have an answer.\n",
    "    provided context: {{$db_record}}\n",
    "\n",
    "    User: {{$query_term}}\n",
    "    Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function = kernel.create_semantic_function(prompt, max_tokens=500, temperature=0.0, top_p=0.5)\n",
    "context = kernel.create_new_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "context['query_term'] = query_term\n",
    "context['db_record'] = result[0].additional_metadata\n",
    "completions_result = await chat_function.invoke(context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context is highly relevant to your question. Azure SQL Managed Instance is a fully managed, scalable, and secure SQL Server instance hosted in Azure. It provides features like automatic backups, monitoring, and high availability. It is a database service that allows you to migrate your existing applications, build new applications, and ensure the performance and security of your data.\n"
     ]
    }
   ],
   "source": [
    "print(completions_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Hey how are you?\n",
      "Response: The provided context is about Azure Event Hubs. The question is not relevant to the context. Can I help you with anything related to Azure Event Hubs?\n",
      "Question: What is Azure App Service?\n",
      "Response: The question is highly relevant with a score of 1. Azure App Service is a fully managed platform for building, deploying, and scaling web apps. It supports a variety of programming languages and frameworks, such as .NET, Java, Node.js, Python, and PHP. You can host web apps, mobile app backends, and RESTful APIs on it. It also offers built-in auto-scaling and load balancing capabilities and integrates with other Azure services, such as Azure DevOps, GitHub, and Bitbucket.\n",
      "Question: exit\n",
      "Response: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "query_term = \"\"\n",
    "while True and query_term != \"exit\":\n",
    "    query_term = input(\"Enter a query: \")\n",
    "    result = await kernel.memory.search(collection_name, query_term)\n",
    "    context['query_term'] = query_term\n",
    "    context['db_record'] = result[0].additional_metadata\n",
    "    completions_result = await chat_function.invoke(context=context)\n",
    "    print(f\"Question:\\n{query_term}\\nResponse:\\n{completions_result}\")\n",
    "    time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
