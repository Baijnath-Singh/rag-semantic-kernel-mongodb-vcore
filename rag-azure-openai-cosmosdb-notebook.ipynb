{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install the Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade semantic-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create your environment variables .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your environment variables then run the cell to create the *.env* file with your environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile .env\n",
    "# Environment variables obtained from Azure OpenAI\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_ENDPOINT=\"\"\n",
    "AZURE_OPENAI_API_KEY=\"\"\n",
    "# Environment variable obtained from Azure Cosmos DB for MongoDB vCore\n",
    "AZCOSMOS_CONNSTR=\"\"\n",
    "# Environment variables you set to be used by the code\n",
    "AZCOSMOS_API=\"mongo-vcore\" # currently, semantic kernel only supports vCore\n",
    "AZCOSMOS_DATABASE_NAME=\"\"\n",
    "AZCOSMOS_CONTAINER_NAME=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the environment variables file\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the parameters needed by [Azure Cosmos DB for MongoDB vCore](https://learn.microsoft.com/azure/cosmos-db/mongodb/vcore/vector-search) to create the vector search index are handled by semantic kernel.\n",
    "\n",
    "In this guide, we are using `text-embedding-ada-002` embedding model to generate the embeddings which uses a 1536-dimensional embedding vector.\n",
    "\n",
    "The `num_lists` is an integer that represents of clusters that the inverted file (IVF) index uses to group the vector data.\n",
    "\n",
    "The `similarity` used with IVF index here is the `COS` (cosine distance) but you can also try `L2` (Euclidean distance), and `IP` (inner product). For more information see the [Understand embeddings in Azure OpenAI Service article](https://learn.microsoft.com/azure/ai-services/openai/concepts/understand-embeddings#cosine-similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection name will be used multiple times in the code so we store it in a variable\n",
    "collection_name = config.get(\"AZCOSMOS_CONTAINER_NAME\")\n",
    "\n",
    "# Vector search index parameters\n",
    "index_name = \"VectorSearchIndex\"\n",
    "vector_dimensions = 1536 # text-embedding-ada-002 uses a 1536-dimensional embedding vector\n",
    "num_lists = 1\n",
    "similarity = \"COS\" # cosine distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "async def upsert_data_to_memory_store(kernel_memory_store: callable, memory_store: callable, data_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    This asynchronous function takes a memory store and a data file path as arguments. \n",
    "    It is designed to upsert (update or insert) data into the memory store from the data file.\n",
    "\n",
    "    Args:\n",
    "        memory_store (callable): A callable object that represents the memory store where data will be upserted.\n",
    "        data_file_path (str): The path to the data file that contains the data to be upserted.\n",
    "\n",
    "    Returns:\n",
    "        None. The function performs an operation that modifies the memory store in-place.\n",
    "    \"\"\"\n",
    "    with open(file=data_file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        n = 0\n",
    "        for item in data:\n",
    "            n+=1\n",
    "            \n",
    "            if not await memory_store.get(collection_name, item[\"id\"], with_embedding=True):\n",
    "                await kernel_memory_store.save_information(\n",
    "                    collection=collection_name,\n",
    "                    id=item[\"id\"],\n",
    "                    text=item[\"content\"],\n",
    "                    description=item[\"title\"]\n",
    "                )\n",
    "                print(\"Generating embeddings and saving new item:\", n, \"/\" ,len(data), end='\\r')\n",
    "            else:\n",
    "                print(\"Skipping item already exits:\", n, \"/\" ,len(data), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Add the Chat and Embedding models to the Semantic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "# get api key and endpoint from .env file\n",
    "_, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "kernel = sk.Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding azure openai chat service\n",
    "chat_model_deployment_name = config.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "azure_chat_service = AzureChatCompletion(\n",
    "    deployment_name=chat_model_deployment_name,\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Azure OpenAI Chat Service...\n"
     ]
    }
   ],
   "source": [
    "kernel.add_chat_service(chat_model_deployment_name, azure_chat_service)\n",
    "print(\"Added Azure OpenAI Chat Service...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding azure openai text embedding service\n",
    "embedding_model_deployment_name = config.get(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\")\n",
    "\n",
    "azure_text_embedding_service = AzureTextEmbedding(\n",
    "    deployment_name=embedding_model_deployment_name,\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Azure OpenAI Embedding Generation Service...\n"
     ]
    }
   ],
   "source": [
    "kernel.add_text_embedding_generation_service(embedding_model_deployment_name, azure_text_embedding_service)\n",
    "print(\"Added Azure OpenAI Embedding Generation Service...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create or Update Azure Cosmos DB for MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating or updating Azure Cosmos DB Memory Store...\n",
      "Finished updating Azure Cosmos DB Memory Store...\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cosmosdb import (\n",
    "    AzureCosmosDBMemoryStore,\n",
    ")\n",
    "\n",
    "print(\"Creating or updating Azure Cosmos DB Memory Store...\")\n",
    "# create azure cosmos db for mongo db vcore api store and collection with vector ivf\n",
    "# currently, semantic kernel only supports the ivf vector kind\n",
    "store  = await AzureCosmosDBMemoryStore.create(\n",
    "    database_name=config.get(\"AZCOSMOS_DATABASE_NAME\"),\n",
    "    collection_name=collection_name,\n",
    "    index_name=index_name,\n",
    "    vector_dimensions=vector_dimensions,\n",
    "    num_lists=num_lists,\n",
    "    similarity=similarity\n",
    ")\n",
    "print(\"Finished updating Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered Azure Cosmos DB Memory Store...\n"
     ]
    }
   ],
   "source": [
    "kernel.register_memory_store(memory_store=store)\n",
    "print(\"Registered Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generate embeddings and Create Database records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting data to Azure Cosmos DB Memory Store...\n",
      "Skipping item already exits: 107 / 107\r"
     ]
    }
   ],
   "source": [
    "print(\"Upserting data to Azure Cosmos DB Memory Store...\")\n",
    "await upsert_data_to_memory_store(kernel.memory, store, \"./text-sample.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Test the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each time it calls the embedding model to generate embeddings from your query\n",
    "query_term = \"What is Azure Database for Managed Instances?\"\n",
    "result = await kernel.memory.search(collection_name, query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is: Azure SQL Managed Instance is a fully managed, scalable, and secure SQL Server instance hosted in Azure. It provides features like automatic backups, monitoring, and high availability. SQL Managed Instance supports various data types, such as JSON, spatial, and full-text. You can use Azure SQL Managed Instance to migrate your existing applications, build new applications, and ensure the performance and security of your data. It also integrates with other Azure services, such as Azure App Service and Azure Data Factory.\n",
      "Relevance Score: 0.8967783841391536\n",
      "Full Record: {\"text\": \"Azure SQL Managed Instance is a fully managed, scalable, and secure SQL Server instance hosted in Azure. It provides features like automatic backups, monitoring, and high availability. SQL Managed Instance supports various data types, such as JSON, spatial, and full-text. You can use Azure SQL Managed Instance to migrate your existing applications, build new applications, and ensure the performance and security of your data. It also integrates with other Azure services, such as Azure App Service and Azure Data Factory.\", \"description\": \"Azure SQL Managed Instance\", \"additional_metadata\": null}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Result is: {result[0].text}\\nRelevance Score: {result[0].relevance}\\nFull Record: {result[0].additional_metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Create chat function with Azure OpenAI chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a chatbot that can have a conversations about any topic related to the provided context.\n",
    "    Start by saying how relevant the question is using the provided context relevancy score.\n",
    "    Give explicit answers from the provided context or say 'I don't know' if it does not have an answer.\n",
    "    provided context: {{$db_record}}\n",
    "\n",
    "    User: {{$query_term}}\n",
    "    Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function = kernel.create_semantic_function(prompt, max_tokens=500, temperature=0.0, top_p=0.5)\n",
    "context = kernel.create_new_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "context['query_term'] = query_term\n",
    "context['db_record'] = result[0].additional_metadata\n",
    "completions_result = await chat_function.invoke(context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context is highly relevant to your question. Azure SQL Managed Instance is a fully managed, scalable, and secure SQL Server instance hosted in Azure. It provides features like automatic backups, monitoring, and high availability. It is a database service that allows you to migrate your existing applications, build new applications, and ensure the performance and security of your data.\n"
     ]
    }
   ],
   "source": [
    "print(completions_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Testing the whole flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What is a service I can use to host my website?\n",
      "Response:\n",
      "The Azure App Service is a fully managed platform for building, deploying, and scaling web apps. It supports a variety of programming languages and frameworks, such as .NET, Java, Node.js, Python, and PHP. You can use it to host web apps, mobile app backends, and RESTful APIs. So, it is a great option for hosting your website. The relevancy score for this question is high.\n",
      "Question:\n",
      "What is the best no sql database available on Azure?\n",
      "Response:\n",
      "The provided context describes Azure Cosmos DB as a fully managed, globally distributed, multi-model database service that supports popular NoSQL APIs, including MongoDB, Cassandra, Gremlin, and Azure Table Storage. Therefore, Azure Cosmos DB can be considered as one of the best NoSQL databases available on Azure. The relevancy score for this question is high.\n",
      "Question:\n",
      "exit\n",
      "Response:\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "query_term = \"\"\n",
    "while query_term != \"exit\":\n",
    "    query_term = input(\"Enter a query: \")\n",
    "    result = await kernel.memory.search(collection_name, query_term)\n",
    "    context['query_term'] = query_term\n",
    "    context['db_record'] = result[0].additional_metadata\n",
    "    completions_result = await chat_function.invoke(context=context)\n",
    "    print(f\"Question:\\n{query_term}\\nResponse:\\n{completions_result}\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
